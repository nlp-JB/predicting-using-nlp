{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import explore\n",
    "import modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = explore.make_initial_df()\n",
    "df = explore.add_new_columns(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = explore.bin_link_counts(df)\n",
    "df = explore.bin_word_counts(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0000</th>\n",
       "      <th>000000</th>\n",
       "      <th>00008100</th>\n",
       "      <th>0001twosumproblems1twosumenmd</th>\n",
       "      <th>0002</th>\n",
       "      <th>0003</th>\n",
       "      <th>0004732</th>\n",
       "      <th>0004medianoftwosortedarrayproblems4medianoftwosortedarraymd</th>\n",
       "      <th>...</th>\n",
       "      <th>provide+</th>\n",
       "      <th>recommend+</th>\n",
       "      <th>release+</th>\n",
       "      <th>require+</th>\n",
       "      <th>run+</th>\n",
       "      <th>start+</th>\n",
       "      <th>support+</th>\n",
       "      <th>use+</th>\n",
       "      <th>work+</th>\n",
       "      <th>politeness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.065301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001941</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014578</td>\n",
       "      <td>0.03761</td>\n",
       "      <td>0.030403</td>\n",
       "      <td>0.030292</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.056998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 41817 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    00  000  0000  000000  00008100  0001twosumproblems1twosumenmd  0002  \\\n",
       "0  0.0  0.0   0.0     0.0       0.0                            0.0   0.0   \n",
       "1  0.0  0.0   0.0     0.0       0.0                            0.0   0.0   \n",
       "2  0.0  0.0   0.0     0.0       0.0                            0.0   0.0   \n",
       "3  0.0  0.0   0.0     0.0       0.0                            0.0   0.0   \n",
       "4  0.0  0.0   0.0     0.0       0.0                            0.0   0.0   \n",
       "\n",
       "   0003  0004732  0004medianoftwosortedarrayproblems4medianoftwosortedarraymd  \\\n",
       "0   0.0      0.0                                                0.0             \n",
       "1   0.0      0.0                                                0.0             \n",
       "2   0.0      0.0                                                0.0             \n",
       "3   0.0      0.0                                                0.0             \n",
       "4   0.0      0.0                                                0.0             \n",
       "\n",
       "   ...  provide+  recommend+  release+  require+      run+   start+  support+  \\\n",
       "0  ...       0.0         0.0       0.0       0.0  0.000000  0.00000  0.000000   \n",
       "1  ...       0.0         0.0       0.0       0.0  0.000000  0.00000  0.000000   \n",
       "2  ...       0.0         0.0       0.0       0.0  0.001941  0.00000  0.000000   \n",
       "3  ...       0.0         0.0       0.0       0.0  0.000000  0.00000  0.000000   \n",
       "4  ...       0.0         0.0       0.0       0.0  0.014578  0.03761  0.030403   \n",
       "\n",
       "       use+  work+  politeness  \n",
       "0  0.000000    0.0    0.000000  \n",
       "1  0.000000    0.0    0.065301  \n",
       "2  0.000000    0.0    0.000000  \n",
       "3  0.000000    0.0    0.000000  \n",
       "4  0.030292    0.0    0.056998  \n",
       "\n",
       "[5 rows x 41817 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make vectorized_df\n",
    "vectorized_df = explore.make_vectorized_df(df)\n",
    "# add new columns to vectorized_df\n",
    "vectorized_df = explore.aggregate_columns(vectorized_df)\n",
    "vectorized_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>279</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>156</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               actual\n",
       "279        JavaScript\n",
       "156  Jupyter Notebook\n",
       "31             Python\n",
       "125        JavaScript\n",
       "110             other"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scale and make test predictions dfs\n",
    "X_train_scaled, X_test_scaled, y_train, y_test, train_predictions, test_predictions = explore.get_splits(df, vectorized_df)\n",
    "# reduce the vectorized dataframe \n",
    "X_train_reduced, X_test_reduced = explore.prep_vectorized_df(X_train_scaled, X_test_scaled)\n",
    "\n",
    "train_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# make predictions\n",
    "train_predictions, test_predictions = modeling.make_predictions_df(X_train_reduced, X_test_reduced, y_train, train_predictions, test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>baseline</th>\n",
       "      <th>lr_predictions</th>\n",
       "      <th>rf_predictions</th>\n",
       "      <th>knn_predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>279</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>Python</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>156</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td>Python</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>Python</td>\n",
       "      <td>Python</td>\n",
       "      <td>Python</td>\n",
       "      <td>Python</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>Python</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>other</td>\n",
       "      <td>Python</td>\n",
       "      <td>other</td>\n",
       "      <td>Python</td>\n",
       "      <td>Java</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               actual baseline    lr_predictions    rf_predictions  \\\n",
       "279        JavaScript   Python        JavaScript        JavaScript   \n",
       "156  Jupyter Notebook   Python  Jupyter Notebook  Jupyter Notebook   \n",
       "31             Python   Python            Python            Python   \n",
       "125        JavaScript   Python        JavaScript        JavaScript   \n",
       "110             other   Python             other            Python   \n",
       "\n",
       "      knn_predictions  \n",
       "279        JavaScript  \n",
       "156  Jupyter Notebook  \n",
       "31         JavaScript  \n",
       "125        JavaScript  \n",
       "110              Java  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics for Logistic Regression Model\n",
      "\n",
      "\n",
      "Accuracy: 91.83%\n",
      "----------------------------------------------------------------------------------------------\n",
      "Confusion Matrix\n",
      "actual            C++  Java  JavaScript  Jupyter Notebook  Python  TypeScript  \\\n",
      "lr_predictions                                                                  \n",
      "C++                14     0           0                 0       0           0   \n",
      "Java                0     5           0                 0       0           0   \n",
      "JavaScript          2     0          45                 1       1           1   \n",
      "Jupyter Notebook    0     1           0                27       0           0   \n",
      "Python              0     3           0                 4      62           0   \n",
      "TypeScript          0     0           0                 0       0          14   \n",
      "other               0     0           0                 1       0           0   \n",
      "\n",
      "actual            other  \n",
      "lr_predictions           \n",
      "C++                   0  \n",
      "Java                  0  \n",
      "JavaScript            2  \n",
      "Jupyter Notebook      0  \n",
      "Python                1  \n",
      "TypeScript            0  \n",
      "other                24  \n",
      "----------------------------------------------------------------------------------------------\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "             C++       1.00      0.88      0.93        16\n",
      "            Java       1.00      0.56      0.71         9\n",
      "      JavaScript       0.87      1.00      0.93        45\n",
      "Jupyter Notebook       0.96      0.82      0.89        33\n",
      "          Python       0.89      0.98      0.93        63\n",
      "      TypeScript       1.00      0.93      0.97        15\n",
      "           other       0.96      0.89      0.92        27\n",
      "\n",
      "        accuracy                           0.92       208\n",
      "       macro avg       0.95      0.87      0.90       208\n",
      "    weighted avg       0.93      0.92      0.92       208\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluation Metrics for Random Forest Model\n",
      "\n",
      "\n",
      "Accuracy: 61.06%\n",
      "----------------------------------------------------------------------------------------------\n",
      "Confusion Matrix\n",
      "actual            C++  Java  JavaScript  Jupyter Notebook  Python  TypeScript  \\\n",
      "rf_predictions                                                                  \n",
      "C++                 2     0           0                 0       0           0   \n",
      "JavaScript          3     6          42                 2       2          13   \n",
      "Jupyter Notebook    0     0           0                22       0           0   \n",
      "Python             11     3           3                 9      61           2   \n",
      "\n",
      "actual            other  \n",
      "rf_predictions           \n",
      "C++                   0  \n",
      "JavaScript           17  \n",
      "Jupyter Notebook      0  \n",
      "Python               10  \n",
      "----------------------------------------------------------------------------------------------\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "             C++       1.00      0.12      0.22        16\n",
      "            Java       0.00      0.00      0.00         9\n",
      "      JavaScript       0.49      0.93      0.65        45\n",
      "Jupyter Notebook       1.00      0.67      0.80        33\n",
      "          Python       0.62      0.97      0.75        63\n",
      "      TypeScript       0.00      0.00      0.00        15\n",
      "           other       0.00      0.00      0.00        27\n",
      "\n",
      "        accuracy                           0.61       208\n",
      "       macro avg       0.44      0.38      0.35       208\n",
      "    weighted avg       0.53      0.61      0.51       208\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluation Metrics for K Nearest Nerighbors Model\n",
      "\n",
      "\n",
      "Accuracy: 59.13%\n",
      "----------------------------------------------------------------------------------------------\n",
      "Confusion Matrix\n",
      "actual            C++  Java  JavaScript  Jupyter Notebook  Python  TypeScript  \\\n",
      "knn_predictions                                                                 \n",
      "C++                14     0           2                 1       3           1   \n",
      "Java                1     7           3                 4      11           2   \n",
      "JavaScript          0     2          38                 2      12           6   \n",
      "Jupyter Notebook    0     0           0                25       2           1   \n",
      "Python              1     0           0                 1      33           0   \n",
      "TypeScript          0     0           2                 0       2           4   \n",
      "other               0     0           0                 0       0           1   \n",
      "\n",
      "actual            other  \n",
      "knn_predictions          \n",
      "C++                   2  \n",
      "Java                  5  \n",
      "JavaScript           10  \n",
      "Jupyter Notebook      4  \n",
      "Python                3  \n",
      "TypeScript            1  \n",
      "other                 2  \n",
      "----------------------------------------------------------------------------------------------\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "             C++       0.61      0.88      0.72        16\n",
      "            Java       0.21      0.78      0.33         9\n",
      "      JavaScript       0.54      0.84      0.66        45\n",
      "Jupyter Notebook       0.78      0.76      0.77        33\n",
      "          Python       0.87      0.52      0.65        63\n",
      "      TypeScript       0.44      0.27      0.33        15\n",
      "           other       0.67      0.07      0.13        27\n",
      "\n",
      "        accuracy                           0.59       208\n",
      "       macro avg       0.59      0.59      0.51       208\n",
      "    weighted avg       0.68      0.59      0.57       208\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "evaluation_report = modeling.train_evaluation(train_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_evaluation(test_predictions):\n",
    "    # Logistic regression accuracy score, confustion matrix, classification report for test data\n",
    "    print('Evaluation Metrics for Logistic Regression Model')\n",
    "    print()\n",
    "    print()\n",
    "    print('Accuracy: {:.2%}'.format(accuracy_score(test_predictions.actual, test_predictions.lr_predictions)))\n",
    "    print('----------------------------------------------------------------------------------------------')\n",
    "    print('Confusion Matrix')\n",
    "    print(pd.crosstab(test_predictions.lr_predictions, test_predictions.actual))\n",
    "    print('----------------------------------------------------------------------------------------------')\n",
    "    print(classification_report(test_predictions.actual, test_predictions.lr_predictions))\n",
    "\n",
    "    print()\n",
    "    print()\n",
    "    print()\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics for Logistic Regression Model\n",
      "\n",
      "\n",
      "Accuracy: 54.44%\n",
      "----------------------------------------------------------------------------------------------\n",
      "Confusion Matrix\n",
      "actual            C++  Java  JavaScript  Jupyter Notebook  Python  TypeScript  \\\n",
      "lr_predictions                                                                  \n",
      "C++                 3     0           0                 1       0           0   \n",
      "JavaScript          1     0          14                 0       1           5   \n",
      "Jupyter Notebook    0     0           0                 6       1           0   \n",
      "Python              2     3           4                 7      24           0   \n",
      "TypeScript          0     0           1                 0       0           2   \n",
      "other               1     1           1                 0       1           0   \n",
      "\n",
      "actual            other  \n",
      "lr_predictions           \n",
      "C++                   0  \n",
      "JavaScript            0  \n",
      "Jupyter Notebook      1  \n",
      "Python               10  \n",
      "TypeScript            0  \n",
      "other                 0  \n",
      "----------------------------------------------------------------------------------------------\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "             C++       0.75      0.43      0.55         7\n",
      "            Java       0.00      0.00      0.00         4\n",
      "      JavaScript       0.67      0.70      0.68        20\n",
      "Jupyter Notebook       0.75      0.43      0.55        14\n",
      "          Python       0.48      0.89      0.62        27\n",
      "      TypeScript       0.67      0.29      0.40         7\n",
      "           other       0.00      0.00      0.00        11\n",
      "\n",
      "        accuracy                           0.54        90\n",
      "       macro avg       0.47      0.39      0.40        90\n",
      "    weighted avg       0.52      0.54      0.50        90\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_evaluation(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      medium\n",
       "1       small\n",
       "2       small\n",
       "3       small\n",
       "4      medium\n",
       "        ...  \n",
       "293     small\n",
       "294     small\n",
       "295     small\n",
       "296     small\n",
       "297     small\n",
       "Name: link_bins, Length: 298, dtype: category\n",
       "Categories (3, object): [small < medium < large]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.link_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make train and test precitions dataframe starting with actual values\n",
    "# train_predictions = pd.DataFrame(y_train)\n",
    "# train_predictions.columns = ['actual']\n",
    "# test_predictions = pd.DataFrame(y_test)\n",
    "# test_predictions.columns = ['actual']\n",
    "\n",
    "# add baseline to predictions dataframe\n",
    "# train_predictions['baseline'] = 'Python'\n",
    "# test_predictions['baseline'] = 'Python'\n",
    "# train_predictions\n",
    "\n",
    "# test_predictions\n",
    "\n",
    "# train, test = modeling.logistic_regression(df, vectorized_df)\n",
    "\n",
    "# train\n",
    "\n",
    "# rf = RandomForestClassifier(bootstrap=True, \n",
    "#                             class_weight=None, \n",
    "#                             criterion='gini',\n",
    "#                             min_samples_leaf=3,\n",
    "#                             n_estimators=100,\n",
    "#                             max_depth=3, \n",
    "#                             random_state=123)\n",
    "\n",
    "# rf.fit(X_train, y_train)\n",
    "\n",
    "# train_random_forest_predictions = rf.predict(X_train)\n",
    "# test_random_forest_predictions = rf.predict(X_test)\n",
    "\n",
    "# knn = KNeighborsClassifier(n_neighbors=5, weights='uniform')\n",
    "\n",
    "# knn.fit(X_train, y_train)\n",
    "\n",
    "# train_knn_predictions = knn.predict(X_train)\n",
    "# test_knn_predictions = knn.predict(X_test)\n",
    "\n",
    "# X_train_scaled, X_test_scaled, X_train_reduced, X_test_reduced = explore.prep_vectorized_df(df, vectorized_df)\n",
    "\n",
    "# X_train_scaled, X_test_scaled, X_train_reduced, X_test_reduced = modeling.make_predictions_df(df, vectorized_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
